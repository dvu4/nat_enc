{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Noise as Target (NAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "##### Idea : \n",
    "\n",
    "- predict images from learnable noise\n",
    "\n",
    "- learn representations by mapping data to to randomly sampled noise vectors.\n",
    "\n",
    "- use random labels to train a network, then use the learned features to do other tasks [(Link1)](http://ruotianluo.github.io/2017/06/28/predict-noise/) [(Link2)](http://www.inference.vc/unsupervised-learning-by-predicting-noise-an-information-maximization-view-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper :\n",
    "\n",
    "\n",
    "- Setting noise as pseudo target (NAT), we try to find good feature representation/discriminative features to map images to a predefined random vector and differentiate between the images. \n",
    "\n",
    "\n",
    "- Noise or pseudo target is sampled uniformly random latent vector from unit sphere which forces the network to learn features which can be distinguish the images. Given fixed k representations on unit hypersphere, CNN provide n feature representations which are close to chosen feature representations with k > n. \n",
    "\n",
    "\n",
    "- Picking the best assignment P from Hungarian algorithm from P(n, k) choices, we can update subset of assignments and CNN's parameter $\\theta$'s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset : \n",
    "\n",
    "- We focus on the MNIST, CIFAR-10, STL-10, CelebA, and LSUNBedroom datasets\n",
    "\n",
    "- CIFAR-10 [Krizhevsky and Hinton, 2009] is set of images belonging to ten different object categories. We use the original training set, composed of 50,000 color images of size $32 \\times 32$ pixels\n",
    "\n",
    "<img src=\"./cifar-10.png\",width=560,height=560>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "\n",
    "- consider a large set of images {$x_1$, . . . , $x_n$ }, where each image $x_i \\in X$ has dimensions $3\n",
    "\\times w \\times h$. \n",
    "\n",
    "\n",
    "- initialize a set of d-dimensional uniformly random latent vectors {$y_1$, . . . , $y_n$ }, where $y_i \\in Y \\subseteq  \\mathbb{R}\n",
    "^d$ for all i = 1, . . . n. \n",
    "\n",
    "\n",
    "- pair the dataset of images with the random vectors, obtaining the dataset {($y_1, x_1$), . . . ,($y_n , x_n$ )}. \n",
    "\n",
    "\n",
    "- jointly learn the parameters $\\theta$ in $\\Theta$ of a generator $f_\\theta$ (convolutional network)  :\n",
    "$X â†’ Y$ and the optimal noise vector $y_i$ for each image $x_i$ \n",
    "\n",
    "\n",
    "- given a loss $l$, we try to solve the following optimization problem:\n",
    "\n",
    "\n",
    "$$\\min\\limits_{\\theta \\in \\Theta} {1 \\over n} \\sum^n\\limits_{i=1} \\min\\limits_{y_i \\in Y} l(f_\\theta(x_i), y_i)$$\n",
    "\n",
    " $l : X \\times X$ is a loss function measuring the mapping error from $f(x_i)$ to $y_i$\n",
    " \n",
    " <img src=\"./auto_encoder.png\",width=360,height=360>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised learning:\n",
    "\n",
    "suppose we have n samples $x_i$, and each sample has a target $y_i$(not limited to a class), we have to learn a function $f_\\theta$, so that expected loss is minimized,\n",
    "\n",
    "$$\\min\\limits_{\\theta \\in \\Theta} {1 \\over n} \\sum^n\\limits_{i=1} l(f_\\theta(x_i), y_i)$$ \n",
    "\n",
    "#### Unsupervised learning\n",
    "\n",
    "we do not have this target $y_i$, we have to learn the $y_i$. So the objective now becomes:\n",
    "\n",
    "\n",
    "$$\\min\\limits_{\\theta \\in \\Theta} {1 \\over n} \\min\\limits_{y_i}  \\sum^n\\limits_{i=1} l(f_\\theta(x_i), y_i)$$\n",
    "\n",
    "To avoid all $y_is$ are constant, then $f_\\theta$ outputs this constant all the time, we should put constraints on $y_i$.\n",
    "\n",
    " - choose k representations in advance (  k > n ; these k representations are fixed), \n",
    " \n",
    " \n",
    " - then $y_i$ must be selected from the k representations, and the same representation can only be chosen by one $y_i$.\n",
    " \n",
    "\n",
    "<img src=\"./nat1.png\",width=560,height=560>\n",
    "\n",
    "Denote in matrix form, \n",
    "\n",
    " - target matrix $Y \\in \\mathbb{R}^{n \\times d}$ (each line is $y_i \\in \\mathbb{R}^{d}$ and d is the length of y)\n",
    " (generate target representation on d-unit-sphere)\n",
    " \n",
    " \n",
    " - matrix $C \\in \\mathbb{R}^{k \\times d}$ , containing pre-selected k representations. (each line is $c_j \\in \\mathbb{R}^{d}$ and d is the length of c) (restricting the representation to the unit sphere )\n",
    "\n",
    "\n",
    " - assignment matrix $P \\in \\mathbb{B}^{n \\times k}$ , with values of {0,1}. \n",
    "     - If $P_{i,j}$ = 1, then $y_i = C_j$. for all i = 1, ...n and all j =1, ...k\n",
    "     - P must satisfy that $P 1_k \\leq 1_n$ , $P^T 1_n = 1_k$. (This is the mathematical form of the above selection constraint)\n",
    "\n",
    "\n",
    " -  Then Y can be represented by matrix factorization $$Y = PC$$\n",
    " \n",
    " \n",
    "So the training objective becomes\n",
    "\n",
    "$$\\min\\limits_{\\theta \\in \\Theta}  \\min\\limits_{P \\in \\{0,1\\}^{n \\times k}} l_2(f_\\theta(X), PC) = \\min\\limits_{\\theta \\in \\Theta}  \\min\\limits_{P} ||f_\\theta(X) -  PC||^2_F$$\n",
    "\n",
    "- Loss: $l_2$ distance\n",
    "\n",
    "- $f_\\theta(x)$: outputs a unit vector of length d\n",
    "\n",
    "- C: uniformly sampled from the unit sphere\n",
    "\n",
    "In nutshell, this algorithm is finding a network that could map all the training data to a unit sphere uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./nat1.png',width=860,height=860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning representations\n",
    "\n",
    " - The idea :  mapping between images and noise to learn generative models is a well known technique [Chen and Gopinath, 2000, Laparra et al., 2011, Sohl-Dickstein et al., 2015, Bordes et al., 2017].\n",
    "\n",
    "\n",
    "- Zhang et al. [2016] realized the capability of deep neural networks to map large collections of images to\n",
    "noise vectors\n",
    "\n",
    "\n",
    "- Bojanowski and Joulin [2017] allow the noise vectors z to move in order to better learn the mapping from images to noise vectors. \n",
    "\n",
    "\n",
    "- The proposed GLO (Generative Latent Optimization) is the analogous to these works, in the opposite direction: learn a map from noise vectors to images. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'r') as f:\n",
    "    datadict = pickle.load(f)\n",
    "    X = datadict['data']\n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(data_dir):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    print('Loading cifar10...')\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(data_dir, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(data_dir, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate target matrix Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Marsaglia-Bray algorithm is the polar method for generating normal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTargetReps(n, z):\n",
    "    \"\"\"\n",
    "    Generate a matrix of random target assignment.\n",
    "    Each target assignment vector has unit length (hence can be view as random point on hypersphere)\n",
    "    :param n: the number of samples to generate.\n",
    "    :param z: the latent space dimensionality\n",
    "    :return: the sampled representations\n",
    "    \"\"\"\n",
    "    # Use Marsaglias algorithm to generate targets on z-unit-sphere\n",
    "    # Generate target matrix Y \n",
    "    \n",
    "    # Generate random targets using gaussian distrib.\n",
    "    samples = np.random.normal(0, 1, [n, z]).astype(np.float32)\n",
    "    \n",
    "    # rescale such that fit on unit sphere.\n",
    "    radiuses = np.expand_dims(np.sqrt(np.sum(np.square(samples),axis=1)),1)\n",
    "    \n",
    "    # return rescaled targets\n",
    "    reps = samples/radiuses\n",
    "    return reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x = np.array([1,2])\n",
    "print(x)\n",
    "print(x.shape, '\\n')\n",
    "\n",
    "y = np.expand_dims(x, axis=0)\n",
    "print(y)\n",
    "print(y.shape, '\\n')\n",
    "\n",
    "z = np.expand_dims(x, axis=1)\n",
    "print(z)\n",
    "print(z.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "samples = np.random.normal(0, 1, [10, 4]).astype(np.float32)\n",
    "radiuses = np.expand_dims(np.sqrt(np.sum(np.square(samples),axis=1)),1)\n",
    "print(samples, '\\n')\n",
    "\n",
    "print(np.square(samples), '\\n')\n",
    "print(np.sum(np.square(samples),axis=1), '\\n')\n",
    "print(np.sqrt(np.sum(np.square(samples),axis=1)), '\\n')\n",
    "print(np.expand_dims(np.sqrt(np.sum(np.square(samples),axis=1)),1), '\\n')\n",
    "print(samples/radiuses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Optimize Assignment with Hungarian Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_optimal_target_permutation(feat_reps, targets):\n",
    "    \"\"\"\n",
    "    Compute the new target assignment that minimizes the SSE between the mini-batch feature space and the targets.\n",
    "\n",
    "    :param feat_reps: the learnt feature representations (given some input images)\n",
    "    :param targets: the currently assigned targets.\n",
    "    :return: the targets reassigned such that the SSE between feature representations and targets is minimized for the batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Optimize Assignment with Hungarian Algorithm\n",
    "    \n",
    "    # Compute cost matrix\n",
    "    cost_matrix = np.zeros([feat_reps.shape[0],targets.shape[0]])\n",
    "    \n",
    "    # Calculate SSE between all features and targets\n",
    "    for i in range(feat_reps.shape[0]):\n",
    "        cost_matrix[:,i] = np.sum(np.square(feat_reps-targets[i,:]),axis=1)\n",
    "\n",
    "    _, col_ind = scipy.optimize.linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Permute the targets based on hungarian algorithm optimization\n",
    "    targets[range(feat_reps.shape[0])] = targets[col_ind]\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(array1, array2):\n",
    "    assert(array1.shape[0]==array2.shape[0])\n",
    "    randomize = np.arange(array1.shape[0])\n",
    "    np.random.shuffle(randomize)\n",
    "    array1 = array1[randomize]\n",
    "    array2 = array2[randomize]\n",
    "    return array1, array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import numpy as np\n",
    "a = np.array([23, 12, 53, 232, 414 , 54 , 313,  131])\n",
    "a.shape[0]\n",
    "randomize = np.arange(a.shape[0])\n",
    "print(randomize)\n",
    "np.random.shuffle(randomize)\n",
    "print(randomize)\n",
    "print(a)\n",
    "print(a[randomize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    print(images.shape)\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images[0:size[0]*size[1], :, :, :]):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    arr = merge(images, size)\n",
    "    print(arr.shape)\n",
    "    return misc.imsave(path,arr)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "<img src=\"./algo.png\",width=400,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tf.reset_default_graph() ](https://github.com/kratzert/finetune_alexnet_with_tensorflow/issues/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cifar10...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import utils\n",
    "np.random.seed(3333)\n",
    "\n",
    "\n",
    "params = dict(batch_size=256,\n",
    "              model_dir='./natenc-cifar10-allclass',\n",
    "              data_dir='./cifar-10-batches-py',\n",
    "              input_type='cifar10',\n",
    "              use_grayscale=False,\n",
    "              use_gradient_images=False,\n",
    "              augment_mlp_training=False,\n",
    "              lr=0.0001,\n",
    "              mlp_lr=0.001,\n",
    "              lr_update_step=10000,\n",
    "              decay_steps=2,\n",
    "              num_epochs=200,\n",
    "              output_every=100,\n",
    "              train_mlp_every=10,\n",
    "              mlp_epochs=50,\n",
    "              z_dim=32,\n",
    "              num_classes=10)\n",
    "\n",
    "\n",
    "# Load cifar\n",
    "data_train, labels_train, data_test, labels_test = utils.load_cifar_XandY(params['data_dir'])\n",
    "\n",
    "# Train data\n",
    "data_train_prep = data_train\n",
    "data_train_mlp = data_train\n",
    "\n",
    "# Test data\n",
    "data_test_prep = data_test\n",
    "\n",
    "# Target reps\n",
    "targetReps = utils.generateTargetReps(data_train.shape[0], params['z_dim']) # z_dim = d\n",
    "\n",
    "# Clears the default graph stack and resets the global default graph\n",
    "tf.reset_default_graph() \n",
    "\n",
    "# setup Model\n",
    "nat_enc = model.NATEnc(params)\n",
    "\n",
    "# MLP reset op\n",
    "mlp_reset_op = tf.variables_initializer(nat_enc.mlp_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 32)\n",
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^mlp_step/Assign\"\n",
      "input: \"^mlp/fully_connected/weights/Assign\"\n",
      "input: \"^mlp/fully_connected/biases/Assign\"\n",
      "input: \"^mlp/fully_connected_1/weights/Assign\"\n",
      "input: \"^mlp/fully_connected_1/biases/Assign\"\n",
      "input: \"^mlp/fully_connected_2/weights/Assign\"\n",
      "input: \"^mlp/fully_connected_2/biases/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "print(data_train_prep.shape)\n",
    "print(data_train_mlp.shape)\n",
    "print(data_test_prep .shape)\n",
    "print(targetReps.shape)\n",
    "print(mlp_reset_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Merge_1/MergeSummary:0\", shape=(), dtype=string)\n",
      "Tensor(\"Merge/MergeSummary:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(nat_enc.mlp_summary_op)\n",
    "print(nat_enc.summary_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./natenc-cifar10-allclass/model.ckpt-1\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:step/sec: 0\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'RuntimeError'>, Attempted to use a closed Session.\n",
      "INFO:tensorflow:step/sec: 0.008333\n",
      "INFO:tensorflow:step/sec: 0\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:step/sec: 0\n",
      "MLP test accuracy: 0.134916\n",
      "MLP Training Epoch 0.9948717948717949 finished, Loss: 2.091677, Accuracy: 0.238281\n",
      "MLP Training Epoch 1.994871794871795 finished, Loss: 1.937781, Accuracy: 0.269531\n",
      "MLP Training Epoch 2.994871794871795 finished, Loss: 1.915006, Accuracy: 0.300781\n",
      "MLP Training Epoch 3.994871794871795 finished, Loss: 1.885322, Accuracy: 0.292969\n",
      "MLP Training Epoch 4.994871794871795 finished, Loss: 1.895539, Accuracy: 0.308594\n",
      "INFO:tensorflow:step/sec: 0\n",
      "MLP test accuracy: 0.321615\n",
      "MLP Training Epoch 5.994871794871795 finished, Loss: 1.868607, Accuracy: 0.316406\n",
      "MLP Training Epoch 6.994871794871795 finished, Loss: 1.936858, Accuracy: 0.281250\n",
      "MLP Training Epoch 7.994871794871795 finished, Loss: 1.790531, Accuracy: 0.324219\n",
      "MLP Training Epoch 8.994871794871795 finished, Loss: 1.859638, Accuracy: 0.324219\n",
      "MLP Training Epoch 9.994871794871795 finished, Loss: 1.903561, Accuracy: 0.332031\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "MLP test accuracy: 0.331430\n",
      "MLP Training Epoch 10.994871794871795 finished, Loss: 1.890467, Accuracy: 0.312500\n",
      "MLP Training Epoch 11.994871794871795 finished, Loss: 1.905831, Accuracy: 0.316406\n",
      "MLP Training Epoch 12.994871794871795 finished, Loss: 1.742215, Accuracy: 0.390625\n",
      "MLP Training Epoch 13.994871794871795 finished, Loss: 1.836120, Accuracy: 0.324219\n",
      "MLP Training Epoch 14.994871794871795 finished, Loss: 1.821872, Accuracy: 0.316406\n",
      "MLP test accuracy: 0.333033\n",
      "MLP Training Epoch 15.994871794871795 finished, Loss: 1.889888, Accuracy: 0.312500\n",
      "MLP Training Epoch 16.994871794871795 finished, Loss: 1.845296, Accuracy: 0.398438\n",
      "MLP Training Epoch 17.994871794871795 finished, Loss: 1.912085, Accuracy: 0.289062\n",
      "MLP Training Epoch 18.994871794871795 finished, Loss: 1.679218, Accuracy: 0.417969\n",
      "MLP Training Epoch 19.994871794871795 finished, Loss: 1.894695, Accuracy: 0.304688\n",
      "MLP test accuracy: 0.326422\n",
      "MLP Training Epoch 20.994871794871795 finished, Loss: 1.766961, Accuracy: 0.363281\n",
      "MLP Training Epoch 21.994871794871795 finished, Loss: 1.771065, Accuracy: 0.359375\n",
      "MLP Training Epoch 22.994871794871795 finished, Loss: 1.774240, Accuracy: 0.363281\n",
      "MLP Training Epoch 23.994871794871795 finished, Loss: 1.714802, Accuracy: 0.378906\n",
      "MLP Training Epoch 24.994871794871795 finished, Loss: 1.693485, Accuracy: 0.371094\n",
      "MLP test accuracy: 0.325220\n",
      "MLP Training Epoch 25.994871794871795 finished, Loss: 1.729575, Accuracy: 0.363281\n",
      "MLP Training Epoch 26.994871794871795 finished, Loss: 1.869828, Accuracy: 0.324219\n",
      "MLP Training Epoch 27.994871794871795 finished, Loss: 1.713960, Accuracy: 0.390625\n",
      "MLP Training Epoch 28.994871794871795 finished, Loss: 1.816424, Accuracy: 0.371094\n",
      "MLP Training Epoch 29.994871794871795 finished, Loss: 1.780432, Accuracy: 0.375000\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "MLP test accuracy: 0.324018\n",
      "MLP Training Epoch 30.994871794871795 finished, Loss: 1.747953, Accuracy: 0.375000\n",
      "MLP Training Epoch 31.994871794871795 finished, Loss: 1.723146, Accuracy: 0.382812\n",
      "MLP Training Epoch 32.99487179487179 finished, Loss: 1.654813, Accuracy: 0.429688\n",
      "MLP Training Epoch 33.99487179487179 finished, Loss: 1.664704, Accuracy: 0.378906\n",
      "MLP Training Epoch 34.99487179487179 finished, Loss: 1.709023, Accuracy: 0.394531\n",
      "MLP test accuracy: 0.327123\n",
      "MLP Training Epoch 35.99487179487179 finished, Loss: 1.660436, Accuracy: 0.386719\n",
      "MLP Training Epoch 36.99487179487179 finished, Loss: 1.709737, Accuracy: 0.414062\n",
      "MLP Training Epoch 37.99487179487179 finished, Loss: 1.675071, Accuracy: 0.414062\n",
      "MLP Training Epoch 38.99487179487179 finished, Loss: 1.687672, Accuracy: 0.363281\n",
      "MLP Training Epoch 39.99487179487179 finished, Loss: 1.736702, Accuracy: 0.398438\n",
      "MLP test accuracy: 0.324119\n",
      "MLP Training Epoch 40.99487179487179 finished, Loss: 1.739266, Accuracy: 0.386719\n",
      "MLP Training Epoch 41.99487179487179 finished, Loss: 1.666975, Accuracy: 0.429688\n",
      "MLP Training Epoch 42.99487179487179 finished, Loss: 1.721594, Accuracy: 0.371094\n",
      "MLP Training Epoch 43.99487179487179 finished, Loss: 1.613465, Accuracy: 0.449219\n",
      "MLP Training Epoch 44.99487179487179 finished, Loss: 1.663279, Accuracy: 0.394531\n",
      "MLP test accuracy: 0.316006\n",
      "MLP Training Epoch 45.99487179487179 finished, Loss: 1.644346, Accuracy: 0.433594\n",
      "MLP Training Epoch 46.99487179487179 finished, Loss: 1.593275, Accuracy: 0.472656\n",
      "MLP Training Epoch 47.99487179487179 finished, Loss: 1.681735, Accuracy: 0.402344\n",
      "MLP Training Epoch 48.99487179487179 finished, Loss: 1.545080, Accuracy: 0.464844\n",
      "MLP Training Epoch 49.99487179487179 finished, Loss: 1.674847, Accuracy: 0.429688\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 0, Step [100/195] Loss: 1.974828\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 1, Step [5/195] Loss: 2.029184\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 1, Step [105/195] Loss: 1.983868\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 2, Step [10/195] Loss: 1.673107\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 2, Step [110/195] Loss: 1.501394\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 3, Step [15/195] Loss: 1.534589\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 3, Step [115/195] Loss: 1.521350\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 4, Step [20/195] Loss: 1.516866\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 4, Step [120/195] Loss: 1.490702\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 5, Step [25/195] Loss: 1.441072\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 5, Step [125/195] Loss: 1.391261\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 6, Step [30/195] Loss: 1.416568\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 6, Step [130/195] Loss: 1.377829\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n",
      "Epoch 7, Step [35/195] Loss: 1.378587\n",
      "INFO:tensorflow:Saving checkpoint to path ./natenc-cifar10-allclass/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#tf.Graph().as_default()\n",
    "#saver = tf.train.Saver()\n",
    "summary_writer = tf.summary.FileWriter(params['model_dir'])\n",
    "sv = tf.train.Supervisor(logdir=params['model_dir'],\n",
    "                        is_chief=True,\n",
    "                        saver=saver,\n",
    "                        summary_op=None,\n",
    "                        summary_writer=summary_writer,\n",
    "                        save_model_secs=300,\n",
    "                        global_step=nat_enc.step,\n",
    "                        ready_for_local_init_op=None)\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                            gpu_options=gpu_options)\n",
    "lr = params['lr']\n",
    "# set up the TF session and init all ops and variables\n",
    "with sv.prepare_or_wait_for_session(config=sess_config) as sess:\n",
    "\n",
    "    batches_per_epoch = data_train_prep.shape[0] / params['batch_size']\n",
    "    batches_per_epoch = int(batches_per_epoch)\n",
    "    counter = 0\n",
    "    curr_epoch = -1\n",
    "    batch_timings = []\n",
    "    decay_steps = 0\n",
    "    for counter in range(params['num_epochs'] * batches_per_epoch):\n",
    "        if counter % batches_per_epoch == 0:\n",
    "            # New epoch\n",
    "            batch_idx = 0\n",
    "            curr_epoch += 1\n",
    "            # Randomize order\n",
    "            targetReps, data_train_prep = utils.shuffle_together(targetReps, data_train_prep)\n",
    "\n",
    "        beg_t = timeit.default_timer()\n",
    "        # Get a batch of samples from training data\n",
    "        batch_x_real = data_train_prep[batch_idx:(batch_idx + params['batch_size'])]\n",
    "        batch_target = targetReps[batch_idx:(batch_idx + params['batch_size'])]\n",
    "        if (curr_epoch +1) % 3 == 0:\n",
    "            # Get Current Representations\n",
    "            feed_dict = {nat_enc.input_train_ph: batch_x_real,nat_enc.dropout_keep_prob:1.0}\n",
    "            fetch_dict = {\n",
    "                    \"reps\": nat_enc.representation\n",
    "                }\n",
    "            result = sess.run(fetch_dict,feed_dict=feed_dict)\n",
    "\n",
    "            # Optimize Assignment with Hungarian Algorithm\n",
    "            batch_target = utils.calc_optimal_target_permutation(result['reps'], batch_target)\n",
    "            targetReps[batch_idx:(batch_idx + params['batch_size'])] = batch_target\n",
    "\n",
    "        # Optimize Network Weights\n",
    "        feed_dict = {nat_enc.targets: batch_target, nat_enc.input_train_ph: batch_x_real,nat_enc.dropout_keep_prob:0.5}\n",
    "\n",
    "        fetch_dict = {\n",
    "                \"train\": nat_enc.train_op\n",
    "            }\n",
    "        if counter % params['output_every'] == 0 and counter!= 0:\n",
    "            fetch_dict.update({\n",
    "                \"summary\": nat_enc.summary_op,\n",
    "                \"loss\": nat_enc.loss\n",
    "            })\n",
    "        result = sess.run(fetch_dict,feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "        end_t = timeit.default_timer()\n",
    "        batch_timings.append(end_t - beg_t)\n",
    "        if counter % params['output_every'] == 0 and counter!= 0:\n",
    "            loss = result['loss']\n",
    "            print(\"Epoch {}, Step [{}/{}] Loss: {:.6f}\". \\\n",
    "                      format(curr_epoch, counter%batches_per_epoch, batches_per_epoch, loss))\n",
    "\n",
    "\n",
    "            summary_writer.add_summary(result['summary'], counter)\n",
    "            summary_writer.flush()\n",
    "\n",
    "        if counter % params['lr_update_step'] == params['lr_update_step'] - 1 and decay_steps<params['decay_steps']:\n",
    "            lr = lr*0.5\n",
    "            decay_steps+=1\n",
    "            sess.run([nat_enc.lr_update],feed_dict={nat_enc.new_lr: lr})\n",
    "\n",
    "        # Train mlp\n",
    "        if curr_epoch % params['train_mlp_every'] == 0 and counter % batches_per_epoch == 0:\n",
    "            # Reset MLP\n",
    "            sess.run(mlp_reset_op)\n",
    "            # Compute Representations\n",
    "            batches_per_epoch = data_train_mlp.shape[0] / params['batch_size']\n",
    "            batches_per_epoch = int(batches_per_epoch)\n",
    "            \n",
    "            mlp_batch_idx = 0\n",
    "            # randomize order\n",
    "            labels_train, data_train_mlp = utils.shuffle_together(labels_train, data_train_mlp)\n",
    "\n",
    "            x_train_mlp = data_train_mlp[:batches_per_epoch*params['batch_size']]\n",
    "            y_train = labels_train[:batches_per_epoch*params['batch_size']]\n",
    "\n",
    "            computed_reps = []\n",
    "            if not params['augment_mlp_training']:\n",
    "                for mlp_step in range(batches_per_epoch):\n",
    "                    batch_x_real = x_train_mlp[mlp_step*params['batch_size']:(mlp_step+1)*params['batch_size']]\n",
    "                    reps = sess.run(nat_enc.representation,\n",
    "                             feed_dict={nat_enc.input_train_ph:batch_x_real,nat_enc.dropout_keep_prob:1.0})\n",
    "                    computed_reps.append(reps)\n",
    "                computed_reps = np.concatenate(computed_reps,axis=0)\n",
    "\n",
    "            for mlp_step in range(params['mlp_epochs']*batches_per_epoch):\n",
    "                if counter % batches_per_epoch == 0:\n",
    "                    # epoch change. First time this if is true, so also init variables.\n",
    "                    mlp_batch_idx = 0\n",
    "                    if params['augment_mlp_training']:\n",
    "                        y_train, x_train_mlp = utils.shuffle_together(y_train, x_train_mlp)\n",
    "                    else:\n",
    "                        y_train, computed_reps = utils.shuffle_together(y_train, computed_reps)\n",
    "\n",
    "                batch_label = y_train[mlp_batch_idx:(mlp_batch_idx + params['batch_size'])]\n",
    "                if params['augment_mlp_training']:\n",
    "                    batch_x = x_train_mlp[mlp_batch_idx:(mlp_batch_idx + params['batch_size'])]\n",
    "                    _, loss, top_k, step = sess.run([nat_enc.mlp_train_op,nat_enc.mlp_loss, nat_enc.mlp_top_k_from_ph, nat_enc.mlp_step],\n",
    "                         feed_dict={nat_enc.mlp_labels:batch_label, nat_enc.input_train_ph:batch_x, nat_enc.dropout_keep_prob:1.0})\n",
    "                else:\n",
    "                    batch_reps = computed_reps[mlp_batch_idx:(mlp_batch_idx + params['batch_size'])]\n",
    "                    _, loss, top_k, step = sess.run([nat_enc.mlp_train_op,nat_enc.mlp_loss, nat_enc.mlp_top_k_from_ph, nat_enc.mlp_step],\n",
    "                         feed_dict={nat_enc.mlp_labels:batch_label, nat_enc.representation_ph:batch_reps})\n",
    "                top_k = np.sum(top_k)\n",
    "\n",
    "                if mlp_step % batches_per_epoch == batches_per_epoch -1:\n",
    "                    print(\"MLP Training Epoch {} finished, Loss: {:.6f}, Accuracy: {:.6f}\". \\\n",
    "                              format(mlp_step/batches_per_epoch, loss, float(top_k)/params['batch_size']))\n",
    "                    tag = 'mlp_train_epoch'+str(curr_epoch)\n",
    "                    train_summary = tf.Summary(value=[tf.Summary.Value(tag=tag+\"/loss\", simple_value=loss),\n",
    "                                             tf.Summary.Value(tag=tag+\"/train_accuracy\", simple_value=float(top_k)/params['batch_size']),\n",
    "                                       ])\n",
    "                    summary_writer.add_summary(train_summary,step)\n",
    "                    summary_writer.flush()\n",
    "\n",
    "                mlp_batch_idx += params['batch_size']\n",
    "                if (mlp_step/batches_per_epoch)%5 == 0 and mlp_step % batches_per_epoch == 0:\n",
    "                    # Test trained MLP\n",
    "                    labels_test, data_test_prep = utils.shuffle_together(labels_test, data_test_prep)\n",
    "                    batches = data_test_prep.shape[0] / params['batch_size']\n",
    "                    batches = int(batches)\n",
    "                    \n",
    "                    correct_pred = 0\n",
    "                    mlp_batch_idx = 0\n",
    "                    for _ in range(batches):\n",
    "                        batch_x_test = data_test_prep[mlp_batch_idx:(mlp_batch_idx + params['batch_size'])]\n",
    "                        batch_label = labels_test[mlp_batch_idx:(mlp_batch_idx + params['batch_size'])]\n",
    "                        top_k = sess.run(nat_enc.mlp_top_k,feed_dict={nat_enc.input_test_ph:batch_x_test, nat_enc.mlp_labels:batch_label,nat_enc.dropout_keep_prob:1.0})\n",
    "                        top_k = np.sum(top_k)\n",
    "                        correct_pred += top_k\n",
    "                        mlp_batch_idx += params['batch_size']\n",
    "\n",
    "                    accuracy = float(correct_pred)/mlp_batch_idx\n",
    "                    print(\"MLP test accuracy: {:.6f}\".format(accuracy))\n",
    "                    tag = 'mlp_train_epoch'+str(curr_epoch)\n",
    "                    test_summary = tf.Summary(value=[tf.Summary.Value(tag=tag+\"/test_accuracy\", simple_value=accuracy)])\n",
    "                    summary_writer.add_summary(test_summary,step)\n",
    "                    summary_writer.flush()\n",
    "\n",
    "\n",
    "        counter += 1\n",
    "        batch_idx += params['batch_size']\n",
    "\n",
    "    print(\"Done training for {} epochs! Elapsed time: {}s\".format(params['num_epochs'], np.sum(batch_timings)))\n",
    "    print(\"Total amount of iterations done: \", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = dict(batch_size=32,\n",
    "              model_dir='./natenc-cifar10-allclass',\n",
    "              data_dir='./cifar-10-batches-py',\n",
    "              out_path='./neighbors_1.png',\n",
    "              input_type='cifar10',\n",
    "              lr=0.0,\n",
    "              mlp_lr=0.0,\n",
    "              use_grayscale=False,\n",
    "              use_gradient_images=False,\n",
    "              augment_mlp_training=False,\n",
    "              z_dim=32,\n",
    "              num_classes=10)\n",
    "\n",
    "num_tests = 1\n",
    "samples = [10,20,30,60,70,90]\n",
    "number_of_neighbors = 5\n",
    "\n",
    "test_batch_size = params['batch_size']\n",
    "\n",
    "# load cifar10\n",
    "data_train, labels_train, data_test, labels_test = utils.load_cifar_XandY(params['data_dir'])\n",
    "\n",
    "data_test_prep = data_test\n",
    "\n",
    "# Setup model\n",
    "nat_enc = model.NATEnc(params)\n",
    "# tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter(params['model_dir'])\n",
    "sv = tf.train.Supervisor(logdir=params['model_dir'], summary_writer=None)\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                            gpu_options=gpu_options)\n",
    "\n",
    "# set up the TF session and init all ops and variables\n",
    "with sv.prepare_or_wait_for_session(config=sess_config) as sess:\n",
    "    cycles = data_test_prep.shape[0]/test_batch_size\n",
    "    results = []\n",
    "    for i in range(cycles):\n",
    "        feed_dict = {nat_enc.input_test_ph: data_test_prep[i*test_batch_size:(i+1)*test_batch_size],\n",
    "                     nat_enc.dropout_keep_prob:1.0}\n",
    "        fetch_dict = {\n",
    "                \"reps\": nat_enc.representation_test,\n",
    "            }\n",
    "        res_test = sess.run(fetch_dict,feed_dict=feed_dict)\n",
    "        results.append(res_test['reps'])\n",
    "    r = np.concatenate(results,axis=0)\n",
    "    images = []\n",
    "    for counter,sample in enumerate(samples):\n",
    "        images.append(np.expand_dims(data_test[sample],axis=0))\n",
    "        img_without = np.concatenate([data_test[:sample,:],data_test[sample+1:,:]],axis=0)\n",
    "        r_without = np.concatenate([r[:sample,:],r[sample+1:,:]],axis=0)\n",
    "        for i in range(number_of_neighbors):\n",
    "            nearest_index = np.sum(np.square(r_without-r[sample]),axis=1).argmin()\n",
    "            images.append(np.expand_dims(img_without[nearest_index],axis=0))\n",
    "            img_without = np.concatenate([img_without[:nearest_index,:],img_without[nearest_index+1:,:]],axis=0)\n",
    "            r_without = np.concatenate([r_without[:nearest_index,:],r_without[nearest_index+1:,:]],axis=0)\n",
    "\n",
    "    printimages = np.concatenate(images,axis=0)\n",
    "    utils.save_images(printimages,[len(samples),number_of_neighbors+1],params['out_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./neighbors.png\",width=360,height=360>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = [10,20,30,60,70,90]\n",
    "\n",
    "for counter,sample in enumerate(samples):\n",
    "    images.append(np.expand_dims(data_test[sample],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
